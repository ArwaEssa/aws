{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49721e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\user\\Downloads\\export_dataframe.csv\")\n",
    "\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1))\n",
    "\n",
    "\n",
    "unigramdataGet= word_vectorizer.fit_transform(data['tweets'].astype('str'))\n",
    "unigramdataGet = unigramdataGet.toarray()\n",
    "\n",
    "vocab = word_vectorizer.get_feature_names()\n",
    "unigramdata_features=pd.DataFrame(np.round(unigramdataGet, 1), columns=vocab)\n",
    "unigramdata_features[unigramdata_features>0] = 1\n",
    "\n",
    "pro= preprocessing.LabelEncoder()\n",
    "encpro=pro.fit_transform(data['class'])\n",
    "data['class'] = encpro \n",
    "\n",
    "y=data['class']\n",
    "X=unigramdata_features\n",
    "\n",
    "# print(X,y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "#\n",
    "LR= LogisticRegression(penalty = 'l2', C = 1)\n",
    "LR.fit(X_train,y_train)\n",
    "pickle.dump(LR,open('awsatmodelupdate.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e12f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "unigramdataGet = unigramdataGet.toarray()\n",
    "\n",
    "vocab = word_vectorizer.get_feature_names()\n",
    "unigramdata_features=pd.DataFrame(np.round(unigramdataGet, 1), columns=vocab)\n",
    "unigramdata_features[unigramdata_features>0] = 1\n",
    "\n",
    "pro= preprocessing.LabelEncoder()\n",
    "encpro=pro.fit_transform(data['class'])\n",
    "data['class'] = encpro \n",
    "\n",
    "y=data['class']\n",
    "X=unigramdata_features\n",
    "\n",
    "# print(X,y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)\n",
    "#\n",
    "LR= LogisticRegression(penalty = 'l2', C = 1)\n",
    "LR.fit(X_train,y_train)\n",
    "pickle.dump(LR,open('awsatmodelupdate.sav','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
